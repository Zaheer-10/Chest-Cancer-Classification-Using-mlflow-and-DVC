{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\soulo\\\\MACHINE_LEARNING_UNIVERSE\\\\PROJECT'S\\\\Chest-Cancer-Classification-Using-mlflow-and-DVC\\\\RESEARCH\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\soulo\\\\MACHINE_LEARNING_UNIVERSE\\\\PROJECT'S\\\\Chest-Cancer-Classification-Using-mlflow-and-DVC\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    # trained_model: Path\n",
    "    # params_weight_decay: float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the config manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chest_Cancer_Classification.constants import *\n",
    "from Chest_Cancer_Classification.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])     \n",
    "        \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.model_trainer\n",
    "        prepare_foundation_model = self.config.prepare_foundation_model\n",
    "        params = self.params\n",
    "        \n",
    "        # training_data = os.path.join(self.config.data_ingestion.unzip_dir , 'Chest-CT-Scan-data')\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chest-CT-Scan-data\")\n",
    "        \n",
    "        create_directories([training.root_dir])\n",
    "        \n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path = Path(training.trained_model_path),\n",
    "            updated_base_model_path = Path(prepare_foundation_model.updated_base_model_path),\n",
    "            training_data = Path(training_data) ,\n",
    "            params_epochs= params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_image_size= params.IMAGE_SIZE,\n",
    "            params_is_augmentation = params.AUGMENTATION,\n",
    "        )\n",
    "        \n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self , config: TrainingConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(self.config.updated_base_model_path)\n",
    "        \n",
    "    def train_valid_generator(self):\n",
    "        '''\n",
    "        `datagenerator_kwargs` is a dictionary containing the arguments for the ImageDataGenerator. It includes a rescale factor of 1/255 to scale the pixel values to the range [0, 1]. It also sets a validation split of 20%.\n",
    "        '''\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        dataflow_kwargs is a dictionary containing the arguments for the data flow. It includes a target size for the images, a batch size, and an interpolation method of \"bilinear\".\n",
    "        '''\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "\n",
    "        ''' \n",
    "        The valid_datagenerator is created using the datagenerator_kwargs and the dataflow_kwargs. It reads the images from the training data directory and treats 20% of them as the validation subset.\n",
    "        '''\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        ''' \n",
    "        If image augmentation is enabled (determined by the config.params_is_augmentation parameter), the train_datagenerator is created with the same parameters as the valid_datagenerator, but also includes additional augmentation parameters like rotation, flipping, and zooming. If augmentation is disabled, the train_datagenerator is set to the valid_datagenerator.\n",
    "        \n",
    "        The valid_generator and train_generator are created using the respective data generators. They read the images from the training data directory and create batches for the model to train on.\n",
    "        \n",
    "        '''\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        ''' \n",
    "        The save_model method is a static method that saves the trained model to a specified path\n",
    "        '''\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        ''' \n",
    "        The train method performs the actual training of the model. It calculates the number of steps per epoch for both the training and validation data. Then, it uses the model.fit method to train the model on the training data for a specified number of epochs, with the validation data used to evaluate the model's performance during training.\n",
    "        '''\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-03 19:26:06,305: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-03 19:26:06,343: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-03 19:26:06,355: INFO: common: created directory at: artifacts]\n",
      "[2023-12-03 19:26:06,361: INFO: common: created directory at: artifacts/training]\n",
      "Found 68 images belonging to 2 classes.\n",
      "Found 275 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 51s 3s/step - loss: 16.8561 - accuracy: 0.5251 - val_loss: 6.4628 - val_accuracy: 0.3906\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 56s 3s/step - loss: 15.0472 - accuracy: 0.5290 - val_loss: 0.0475 - val_accuracy: 0.9844\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 57s 3s/step - loss: 10.5947 - accuracy: 0.5985 - val_loss: 8.7234 - val_accuracy: 0.3906\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 55s 3s/step - loss: 7.7858 - accuracy: 0.7259 - val_loss: 2.6385 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 50s 3s/step - loss: 4.8046 - accuracy: 0.7259 - val_loss: 0.4431 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 55s 3s/step - loss: 5.3747 - accuracy: 0.6911 - val_loss: 1.1674 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.2557 - accuracy: 0.7606 - val_loss: 1.0244 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.6998 - accuracy: 0.8649 - val_loss: 0.0434 - val_accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 49s 3s/step - loss: 3.8100 - accuracy: 0.7876 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 87s 5s/step - loss: 1.3802 - accuracy: 0.8571 - val_loss: 0.1110 - val_accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "except Exception as e:\n",
    "    raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
